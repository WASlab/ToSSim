# Dockerfile for Co-located GRPO training
# Uses the new co-located vLLM approach for maximum efficiency

FROM nvidia/cuda:12.8-devel-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
# CUDA_VISIBLE_DEVICES will be set at runtime for multi-GPU support

# Install system dependencies exactly as in SSH instructions
RUN apt-get update -y && \
    apt-get install -y \
        -o Dpkg::Options::="--force-confdef" \
        -o Dpkg::Options::="--force-confold" \
        software-properties-common \
        build-essential \
        curl \
        git && \
    add-apt-repository ppa:deadsnakes/ppa -y && \
    apt-get update -y && \
    apt-get install -y python3.12 python3.12-venv python3.12-dev && \
    rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy the entire project
COPY . .

# Create virtual environment and install dependencies exactly as in SSH instructions
RUN python3.12 -m venv myenv && \
    . myenv/bin/activate && \
    pip install -U pip setuptools wheel && \
    pip install \
        transformers \
        trl \
        peft \
        accelerate \
        bitsandbytes \
        datasets \
        backoff && \
    pip install https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.10/flash_attn-2.7.4+cu128torch2.7-cp312-cp312-linux_x86_64.whl

# Create a non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Default command - run co-located GRPO training with torchrun
CMD ["/bin/bash", "-c", "source myenv/bin/activate && torchrun --nproc_per_node=1 grpo_colocated.py --config training_configs/dr_grpo_config.yaml"]
