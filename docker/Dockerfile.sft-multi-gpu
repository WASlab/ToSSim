# Multi-GPU SFT training Dockerfile - matches ssh_instructions.txt exactly
# Uses accelerate launch with FSDP for multi-GPU training

FROM nvidia/cuda:12.8-devel-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
# CUDA_VISIBLE_DEVICES will be set at runtime

# Install system dependencies exactly as in SSH instructions
RUN apt-get update -y && \
    apt-get install -y \
        -o Dpkg::Options::="--force-confdef" \
        -o Dpkg::Options::="--force-confold" \
        software-properties-common \
        build-essential \
        curl \
        git && \
    add-apt-repository ppa:deadsnakes/ppa -y && \
    apt-get update -y && \
    apt-get install -y python3.12 python3.12-venv python3.12-dev && \
    rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy the entire project
COPY . .

# Create virtual environment and install dependencies exactly as in SSH instructions
RUN python3.12 -m venv myenv && \
    . myenv/bin/activate && \
    pip install -U pip setuptools wheel && \
    pip install \
        transformers \
        trl \
        peft \
        accelerate \
        bitsandbytes \
        datasets \
        backoff && \
    pip install https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.10/flash_attn-2.7.4+cu128torch2.7-cp312-cp312-linux_x86_64.whl

# Create a non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Default command - activate venv and run multi-GPU training with accelerate launch
CMD ["/bin/bash", "-c", "source myenv/bin/activate && accelerate launch --multi_gpu sft_multi_gpu.py training_configs/gemma_fsdp.json --fsdp_transformer_layer_cls_to_wrap=GemmaDecoderLayer --mixed_precision=bf16"]
