# ----------------------- core -----------------------
model_name: "google/gemma-3-27b-it"

# training
learning_rate: 5.0e-5
min_learning_rate: 4.0e-5
warmup_ticks: 100
gradient_clip_norm: 1.0
batch_size: 15
max_iterations: 5000          # was: max_ticks
log_interval: 2              # was: log_ticks
early_stop_parse_rate: 0.99
early_stop_consecutive_ticks: 1000

# DR‑GRPO
k_per_prompt: 3               # choose your K; 4 is a good default
beta: 0.0                     # no length penalty
sync_frequency: 10            # was: sync_every

# environment
num_games: 1                 # was: num_concurrent_games
active_seats_per_game: 1

# sampling
temperature: 0.8
top_p: 0.9
max_tokens: 96                # was: max_tokens_per_gen
max_think_tokens: 64

# logging / outputs
csv_path: "gemma3-27b_tos_training.csv"
track_weight_deltas: true

# Push-to-Hub (optional — set this if you want auto-publish)
output_hub_repo: ToSSim/gemma3-27b-tos         # e.g. "your-org/gemma3-27b-drgrpo-tos"
hub_private: false
max_shard_size: "10GB"

# ----------------------- FSDP -----------------------
fsdp_config:
  sharding_strategy: "FULL_SHARD"
  sync_state: "SHARDED"       # SHARDED is cheaper for periodic vLLM syncs
  mixed_precision: true
  activation_checkpointing: true
  use_orig_params: true
  offload_full_state_dict_to_cpu: true
  rank0_only_state_dict: true
  checkpoint_dir: "checkpoints/gemma3-27b-tos"

# ----------------------- vLLM -----------------------
vllm_config:
  tensor_parallel_size: 1     
  max_num_seqs: 32
  max_model_len: 32768        
  gpu_memory_utilization: 0.4
  enforce_eager: true
  disable_log_stats: true

disable_vllm: true
quant_mode: "4bit"
only_transformers: true
quant_args:
  bnb_4bit_compute_dtype: "bfloat16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true
  llm_int8_threshold: 6.0
  llm_int8_has_fp16_weight: false

temperature: 0.3            # soften logits; reduce if output is too random
top_p: 0.9                  # 1.0 disables nucleus sampling
top_k: 64                 # null disables top‑k filtering (–1 internally)
min_p: 0.0                  # 0.0 disables probability cutoff
repetition_penalty: 1.0     # discourage exact repetition (tune as needed)

flash_attention: true
liger: true

